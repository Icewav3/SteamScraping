# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŽ® GAME MARKET DATA COLLECTION PIPELINE - MAIN ORCHESTRATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# This is the main workflow that orchestrates all data collection tasks.
# It ensures proper execution order and dependency management.
#
# Execution Order:
#   1. Scrape Phase (parallel execution of all scrapers)
#   2. Compression Phase (waits for all scrapers)
#   3. Upload Phase (parallel upload to multiple destinations)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

name: ðŸš€ Data Collection Pipeline

on:
  # Scheduled execution
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
    # - cron: '0 2 * * 0'  # Weekly on Sunday (uncomment if preferred)
  
  # Manual trigger with configuration options
  workflow_dispatch:
    inputs:
      run_scrapers:
        description: 'Run scraping tasks'
        required: true
        default: true
        type: boolean
      
      steamspy_pages:
        description: 'SteamSpy pages to scrape'
        required: false
        default: '10'
        type: string
      
      steamspy_page_delay:
        description: 'Delay between SteamSpy page requests (seconds)'
        required: false
        default: '0'
        type: string

      steamspy_app_delay:
        description: 'Delay between SteamSpy app detail requests (seconds)'
        required: false
        default: '0'
        type: string

      skip_upload:
        description: 'Skip upload phase (testing only)'
        required: false
        default: false
        type: boolean

# Global environment variables
env:
  DATA_DIR: 'Data'
  PYTHON_VERSION: '3.13'

jobs:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # PHASE 1: SCRAPING (Parallel Execution)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  scrape-steamspy:
    name: ðŸŽ® SteamSpy Scraper
    if: ${{ github.event.inputs.run_scrapers != 'false' }}
    uses: ./.github/workflows/scrape-steamspy.yml
    secrets: inherit
    with:
      pages: ${{ github.event.inputs.steamspy_pages || '10' }}
      page_delay: ${{ github.event.inputs.steamspy_page_delay || '0' }}
      app_delay: ${{ github.event.inputs.steamspy_app_delay || '0' }}
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ðŸ”® FUTURE SCRAPERS - Add new scrapers here
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # 
  # scrape-igdb:
  #   name: ðŸŽ¯ IGDB Scraper
  #   if: ${{ github.event.inputs.run_scrapers != 'false' }}
  #   uses: ./.github/workflows/scrape-igdb.yml
  #   secrets: inherit
  #   with:
  #     max_games: 1000
  #
  # scrape-rawg:
  #   name: ðŸŒ RAWG Scraper
  #   uses: ./.github/workflows/scrape-rawg.yml
  #   secrets: inherit
  #
  # scrape-freetogame:
  #   name: ðŸŽ FreeToGame Scraper
  #   uses: ./.github/workflows/scrape-freetogame.yml
  #   secrets: inherit
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # PHASE 2: COMPRESSION (Waits for all scrapers)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  compress-data:
    name: ðŸ“¦ Compress Data
    needs: 
      - scrape-steamspy
      # Add future scrapers here as dependencies
      # - scrape-igdb
      # - scrape-rawg
      # - scrape-freetogame
    uses: ./.github/workflows/compress.yml
    secrets: inherit
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # PHASE 3: UPLOAD (Parallel Execution)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  upload-to-release:
    name: ðŸ“¤ Upload to GitHub Release
    if: ${{ github.event.inputs.skip_upload != 'true' }}
    needs: compress-data
    permissions:
      contents: write
    uses: ./.github/workflows/upload-release.yml
    secrets: inherit
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ðŸ”® FUTURE UPLOAD DESTINATIONS - Add new destinations here
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  #
  # upload-to-r2:
  #   name: â˜ï¸ Upload to Cloudflare R2
  #   if: ${{ github.event.inputs.skip_upload != 'true' }}
  #   needs: compress-data
  #   uses: ./.github/workflows/upload-r2.yml
  #   secrets: inherit
  #
  # upload-to-gdrive:
  #   name: ðŸ’¾ Upload to Google Drive
  #   needs: compress-data
  #   uses: ./.github/workflows/upload-gdrive.yml
  #   secrets: inherit
  #
  # upload-to-archive:
  #   name: ðŸ“š Upload to Internet Archive
  #   needs: compress-data
  #   uses: ./.github/workflows/upload-archive.yml
  #   secrets: inherit
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # FINAL: NOTIFICATION & CLEANUP
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  finalize:
    name: âœ… Pipeline Complete
    needs:
      - upload-to-release
      # Add future upload jobs here
      # - upload-to-r2
      # - upload-to-gdrive
    runs-on: ubuntu-latest
    
    steps:
      - name: ðŸ“Š Generate Summary
        run: |
          echo "# ðŸŽ‰ Pipeline Execution Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## âœ… Completed Tasks" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Data scraping" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Data compression" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Upload to destinations" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run:** [View Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
      
      - name: ðŸŽŠ Success Notification
        run: |
          echo "âœ… All pipeline tasks completed successfully!"
          echo "ðŸ“¦ Data has been collected, compressed, and uploaded."
          echo "ðŸ”— Check releases for the latest data snapshot."