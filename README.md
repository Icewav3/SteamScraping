# ğŸ® Game Industry Market Analysis

> A powerful data pipeline for scraping, analyzing, and visualizing gaming market trends using SteamSpy data.

[![Python](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/downloads/)
[![Marimo](https://img.shields.io/badge/marimo-0.18.4-orange.svg)](https://marimo.io/)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
---

## ğŸ“‘ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
  - [Step 1: Install UV](#step-1-install-uv)
  - [Step 2: Clone the Repository](#step-2-clone-the-repository)
  - [Step 3: Setup Environment](#step-3-setup-environment)
- [Usage](#-usage)
  - [Running the Scraper](#running-the-scraper)
  - [Running Visualizations](#running-visualizations)
  - [Development Mode](#development-mode)
- [Configuration](#-configuration)
- [Data Output](#-data-output)
- [Troubleshooting](#-troubleshooting)
- [Roadmap](#-roadmap)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

This project provides an automated pipeline for collecting and analyzing gaming market data from SteamSpy. Built with modern async Python and interactive Marimo notebooks, it enables market research, trend analysis, and data-driven decision making for game developers and industry analysts.

**Current Capabilities:**
- ğŸš€ High-performance async scraping with rate limiting
- ğŸ“Š Interactive data visualization with Marimo notebooks
- ğŸ’¾ Automatic daily data organization
- ğŸ”„ Resumable scraping with progress tracking
- ğŸ“ˆ Genre and tag frequency analysis

---

## âœ¨ Features

- **Async Architecture**: Efficient concurrent data fetching with `aiohttp`
- **Rate Limiting**: Respectful API usage with configurable delays
- **Progress Tracking**: Resume interrupted scrapes without data loss
- **Interactive Notebooks**: Marimo-powered reactive analysis
- **Clean Architecture**: Modular design with base scraper class for extensibility
- **Error Handling**: Comprehensive logging and error recovery
- **Daily Organization**: Automatic date-based data storage

---

## ğŸ“ Project Structure

```
steamscraping/
â”œâ”€â”€ ğŸ“‚ Data/                      # Generated during scraping
â”‚   â””â”€â”€ ğŸ“‚ YYYY-MM-DD/            # Daily data folders
â”‚       â”œâ”€â”€ steamspy_data.jsonl   # Main dataset (JSON Lines)
â”‚       â”œâ”€â”€ scraped_appids.txt    # Progress tracking
â”‚       â”œâ”€â”€ metadata.json         # Scrape session info
â”‚       â””â”€â”€ steamspy_errors.log   # Error logs
â”œâ”€â”€ ğŸ“‚ src/                       # Source code
â”‚   â”œâ”€â”€ BaseScraper.py            # Abstract base scraper
â”‚   â”œâ”€â”€ FileSystem.py             # File I/O operations
â”‚   â””â”€â”€ SteamSpyScraper.py        # SteamSpy implementation
â”œâ”€â”€ ğŸ“‚ .vscode/                   # VS Code configuration
â”‚   â”œâ”€â”€ launch.json               # Debug configurations
â”‚   â”œâ”€â”€ settings.json             # Editor settings
â”‚   â””â”€â”€ tasks.json                # Build tasks
â”œâ”€â”€ main.py                       # Scraper notebook
â”œâ”€â”€ visualization.py              # Analysis notebook
â”œâ”€â”€ pyproject.toml                # Project dependencies
â”œâ”€â”€ .python-version               # Python version (3.13)
â””â”€â”€ README.md                     # You are here!
```

---

## ğŸ“‹ Prerequisites

- **Operating System**: Windows, macOS, or Linux
- **Python**: 3.13+ (automatically managed by UV)
- **Internet**: Stable connection for API requests
- **Disk Space**: ~100MB per 10,000 apps scraped

---

## ğŸš€ Installation

### Step 1: Install UV

UV is a fast Python package installer and resolver. Choose your platform:

#### **Windows (PowerShell)**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### **macOS/Linux**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### **Verify Installation**
```bash
uv --version
```

> ğŸ’¡ **Tip**: Restart your terminal after installation to ensure UV is in your PATH.

---

### Step 2: Clone the Repository

```bash
# Clone the repository
git clone https://github.com/Icewav3/SteamScraping
cd steamscraping
```

Or download and extract the ZIP file, then navigate to the folder:
```bash
cd path/to/steamscraping
```

---

### Step 3: Setup Environment

UV will automatically create a virtual environment and install all dependencies:

```bash
# Install all dependencies
uv sync
```

This command:
- âœ… Creates a `.venv` folder with Python 3.13
- âœ… Installs `marimo`, `aiohttp`, and `tqdm`
- âœ… Sets up the project for immediate use

---

## ğŸ’» Usage

### Running the Scraper

Launch the interactive Marimo scraper notebook:

```bash
uv run marimo edit main.py
```

This opens an interactive notebook in your browser where you can:
- Configure scraping parameters (pages, delays)
- Start/stop the scraper
- Monitor real-time progress
- View scraping statistics

**Command Line Alternative** (headless mode):
```bash
uv run marimo run main.py
```

---

### Running Visualizations

Analyze collected data with the visualization notebook:

```bash
uv run marimo edit visualization.py
```

**Features:**
- ğŸ“Š Genre distribution analysis
- ğŸ·ï¸ Tag frequency charts
- ğŸ“ˆ Market trend visualization
- ğŸ¨ Interactive Seaborn plots

---

### Development Mode

#### **Using VS Code**

1. Open the project in VS Code
2. Install the [Marimo extension](https://marketplace.visualstudio.com/items?itemName=marimo-team.vscode-marimo)
3. Press `F5` to launch with debugger attached

#### **Manual Development Server**

```bash
# Run with auto-reload on file changes
uv run marimo edit main.py --watch --port 8888

# Run in sandbox mode (isolated execution)
uv run marimo edit main.py --sandbox
```

---

## âš™ï¸ Configuration

### Scraper Parameters

Edit these in `main.py` or pass to `SteamSpyScraper()`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `pages` | `10` | Number of pages to scrape (~1000 apps each) |
| `page_delay` | `15.0` | Seconds between page requests |
| `app_delay` | `0.1` | Seconds between app detail requests |
| `suppress_output` | `False` | Hide console output |

**Example:**
```python
async with SteamSpyScraper(
    fs, 
    pages=20,           # Scrape 20 pages (~20,000 apps)
    page_delay=10,      # Wait 10s between pages
    app_delay=0.2       # Wait 0.2s between apps
) as scraper:
    await scraper.scrape()
```

---

## ğŸ“¦ Data Output

### File Formats

#### **`steamspy_data.jsonl`**
JSON Lines format - one game per line:
```json
{"appid": 730, "name": "Counter-Strike 2", "developer": "Valve", "owners": "100,000,000 .. 200,000,000", ...}
{"appid": 570, "name": "Dota 2", "developer": "Valve", "owners": "50,000,000 .. 100,000,000", ...}
```

#### **`metadata.json`**
Scrape session information:
```json
{
  "start_time": "2024-12-12T10:30:00",
  "end_time": 1702384500.123,
  "pages_scraped": 10,
  "apps_scraped": 8547
}
```

#### **`scraped_appids.txt`**
List of completed app IDs for resume functionality:
```
730
570
440
...
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### **`uv: command not found`**
- **Solution**: Restart your terminal or add UV to PATH manually
- **Windows**: `%USERPROFILE%\.cargo\bin`
- **Unix**: `~/.cargo/bin`

#### **Rate Limit Errors (HTTP 429)**
- **Solution**: Increase `page_delay` and `app_delay` values
- SteamSpy allows ~1 request per second

#### **Progress Bar Not Showing in Browser**
- **Known Issue**: Marimo progress bars may not render in all browsers
- **Workaround**: Check console output or use `suppress_output=False`

#### **Missing Data Directory**
- Automatically created on first run
- If deleted, will be recreated

#### **Port Already in Use**
```bash
# Use a different port
uv run marimo edit main.py --port 8889
```

---

## ğŸ—ºï¸ Roadmap

### ğŸ”¥ High Priority
- [ ] Complete Marimo migration for native progress bar support
- [ ] Implement data integrity checking script
- [ ] Create time-series comparative analysis notebook
- [ ] Remove unused dependencies

### ğŸ¯ Medium Priority
- [ ] Add multiple data source support (IGDB, Steam Store API)
- [ ] Implement async multi-scraper coordination
- [ ] Design data merging strategy for multi-source accuracy

### ğŸ’¡ Low Priority
- [ ] Enhanced UI with scraper control buttons
- [ ] Advanced genre/tag correlation analysis
- [ ] Export to CSV/Excel formats

### ğŸš€ Long Term
- [ ] Cloud deployment for 24/7 scraping (free tier)
- [ ] Automated backup system (GitHub/cloud storage)
- [ ] Machine learning for market trend prediction
- [ ] Real-time dashboard with live updates

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes**
4. **Test thoroughly**
   ```bash
   uv run marimo edit main.py
   ```
5. **Commit with clear messages**
   ```bash
   git commit -m "Add amazing feature"
   ```
6. **Push and create a Pull Request**
   ```bash
   git push origin feature/amazing-feature
   ```

### Code Style
- Follow PEP 8 guidelines
- Use type hints where possible
- Document all public functions
- Keep modules focused and modular

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[SteamSpy](https://steamspy.com/)** - API provider
- **[Marimo](https://marimo.io/)** - Reactive notebook framework
- **[UV](https://github.com/astral-sh/uv)** - Fast Python package manager

---

## ğŸ“ Support

Having issues? Here's how to get help:

1. **Check [Troubleshooting](#-troubleshooting)** section
2. **Search existing issues** on GitHub
3. **Create a new issue** with:
   - Error message
   - Steps to reproduce
   - System info (`uv --version`, OS)

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ and â˜• for the gaming community

</div>
